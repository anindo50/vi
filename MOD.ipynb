{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "\n",
    "data_dict = dict( product_name = [],\n",
    "                 catagory = [],\n",
    "                 img_link=[],\n",
    "                 price = [],\n",
    "                 UNSPSC = [],\n",
    "                 item_no = [],\n",
    "                 specification_field = [],\n",
    "                 specification_value = [],\n",
    "                 \n",
    "    )\n",
    "\n",
    "def process():\n",
    "    brand_url = \"https://www.henryschein.com/us-en/specialmarkets_d/c/browsesupplies\"\n",
    "    brand_links = parse_item_link(soup_object(brand_url))\n",
    "    product_links = parse_all_link(brand_links)\n",
    "\n",
    "    status = scrape_product_info(product_links)\n",
    "\n",
    "    if status:\n",
    "        export_csv(data_dict)\n",
    "\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_object(url):\n",
    "    login_url = 'https://www.henryschein.com/us-en/Profiles/Login.aspx?redirdone=1'\n",
    "    payload = {'ctl00$ucHeader$ucSessionBar$ucLogin$txtLogonName':'atest3381','ctl00$ucHeader$ucSessionBar$ucLogin$txtPassword':'Atest#3381'}\n",
    "    with req.Session() as s:\n",
    "        post = s.post(login_url,data = payload)\n",
    "        resp = s.get(url)\n",
    "        resp_data = resp.text\n",
    "        soup = BeautifulSoup(resp_data,'html.parser')\n",
    "   \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_item_link(soup):\n",
    "    #cons = soup.find_all('ul',class_='hs-categories display grid clear-fix')\n",
    "    #cat_link = []\n",
    "    man_link = []\n",
    "    #for con in cons:\n",
    "        #link = con.find_all('a')\n",
    "        #link = [i.get('href') for i in link]\n",
    "        #for y in link:\n",
    "            #cat_link.append(y.get('href'))\n",
    "        #cat_link = link\n",
    "        #re_link = cat_link.append(link)\n",
    "    c = soup.find_all('ul',attrs={'data-tabs-contents':'alpha'})\n",
    "    for i in c:\n",
    "        x = i.find_all('a')\n",
    "        for y in x:\n",
    "            f = y.get('href')\n",
    "            man_link.append(f)\n",
    "            print(f)\n",
    "    #total = cat_link,man_link\n",
    "    #total = cat_link,man_link\n",
    "    \n",
    "    print('ok')\n",
    "    return man_link\n",
    "    #return cat_link,man_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_link(links):\n",
    "    \n",
    "    #cat_url = []\n",
    "    man_url = []\n",
    "    for link in links:\n",
    "        \n",
    "        link_soup = soup_object(link)\n",
    "        #x = link_soup.find_all('ul',attrs={'style':'padding: 1em .5em .5em'})\n",
    "        #for i in x:\n",
    "            #z = i.find_all('a')\n",
    "            #for y in z:\n",
    "                #a = y.get('href')\n",
    "                #cat_url.append(a)\n",
    "        m = link_soup.find_all('h2',class_='product-name') \n",
    "        for i in m:\n",
    "            n = i.find_all('a')\n",
    "            for y in n:\n",
    "                p = y.get('href')\n",
    "                man_url.append(p)\n",
    "                print(p)\n",
    "    print('ok')           \n",
    "    #return cat_url,man_url\n",
    "    return man_url\n",
    "\n",
    "#def inside_link(gets):\n",
    "    #hole = []\n",
    "    #for get in gets:\n",
    "        #soup = soup_object(get)\n",
    "        #m = soup.find_all('h2',class_='product-name')\n",
    "        #print(m)\n",
    "        #for i in m:\n",
    "            #n = i.find_all('a')\n",
    "            #for y in n:\n",
    "                #p = y.get('href')\n",
    "               # hole.append(p)\n",
    "   #print('ok')\n",
    "    #return hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  scrape_product_info(product_links):\n",
    "    url = 'https://www.henryschein.com'\n",
    "    for index, product_link in enumerate(product_links):\n",
    "        c = soup_object(product_link)\n",
    "        cols = c.find('h2',class_='heading show-progress active')\n",
    "        for col in cols:\n",
    "            data_dict['product_name'].append(c.find('h2',class_='product-title medium strong').\\\n",
    "            text.replace('\\r','').replace('\\n','').replace('  ','').split('/')[0])\n",
    "            \n",
    "            data_dict['catagory'].append(c.find('ul',class_='small-above').find_next('div',class_='value').text.replace('\\r','').replace('\\n','').replace('  ',''))\n",
    "            \n",
    "            data_dict['UNSPSC'].append(c.find('ul',class_='small-above').find_all('div',class_='value')[1].text.replace('\\r','').replace('\\n','').replace('  ',''))\n",
    "            \n",
    "            data_dict['specification_field'].append(col.find('ul',class_='attr-list').find('div',class_='field').text.replace('\\r','').replace('\\n','').replace('  ',''))\n",
    "            \n",
    "            data_dict['specification_value'].append(col.find('ul',class_='attr-list').find('div',class_='value').text.replace('\\r','').replace('\\n','').replace('  ',''))\n",
    "            \n",
    "            data_dict['item_no'].append(c.find('small',class_='x-small').find_next('strong').text.replace('\\r','').replace('\\n','').replace('  ',''))\n",
    "            \n",
    "            data_dict['img_link'].append((url + c.find('div',class_='hs-product-slideshow').find('img').get('src')))\n",
    "            \n",
    "            data_dict['price'].append(c.find('div',class_='product-price').text.strip())\n",
    "         \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv(data_dict):\n",
    "    dataFrame = pd.DataFrame(data_dict)\n",
    "    dataFrame.to_csv(\"data.csv\", mode='w', header=True, index=False)\n",
    "    print(\"Data.csv exported\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
